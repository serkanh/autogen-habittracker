{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "import os\n",
    "import autogen\n",
    "import pprint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(autogen))\n",
    "print(autogen.__file__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list_gpt4 = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4\", \"gpt-4-0314\", \"gpt4\", \"gpt-4-32k\", \"gpt-4-32k-0314\", \"gpt-4-32k-v0314\"],\n",
    "    },\n",
    ")\n",
    "print(config_list_gpt4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API Key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Path to your image\n",
    "def encode_image_to_base64(image_path):\n",
    "    # This function reads the image file and converts it to a base64 string\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        encoded_string = base64.b64encode(image_file.read()).decode()\n",
    "    return encoded_string\n",
    "\n",
    "def send_image_to_api(image_path):\n",
    "    # Encode the image to base64\n",
    "    base64_image = encode_image_to_base64(image_path)\n",
    "  \n",
    "\n",
    "    # Prepare headers\n",
    "    headers = {\n",
    "      \"Content-Type\": \"application/json\",\n",
    "      \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "\n",
    "    # Prepare payload\n",
    "    payload = {\n",
    "      \"model\": \"gpt-4-vision-preview\",\n",
    "      \"messages\": [\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "            {\n",
    "              \"type\": \"image_url\",\n",
    "              \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "              }\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ],\n",
    "      \"max_tokens\": 300\n",
    "    }\n",
    "\n",
    "    # Send the request\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    return pprint.pprint(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "llm_config = {\n",
    "    \"config_list\": config_list_gpt4,\n",
    "    \"seed\": 42,\n",
    "    \"request_timeout\": 600,\n",
    "    \"temperature\": 0,\n",
    "    \"functions\": [\n",
    "        {\n",
    "            \"name\": \"send_image_to_api\",\n",
    "            \"description\": \"Gets image path and sends it to the API.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"image_path\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Valid path.\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"image_path\"],\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "coder = autogen.AssistantAgent(\n",
    "    name=\"Assistant\",  # the default assistant agent is capable of solving problems with code\n",
    "    system_message=\"\"\"For file uploading functionality use functions that is registered(send_image_to_api) \n",
    "    in the user_proxy agent.\"\"\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "   name=\"user_proxy\",\n",
    "   is_termination_msg=lambda x: x.get(\"content\", \"\") and x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "   human_input_mode=\"NEVER\",\n",
    "   system_message=\"\"\"Reply TERMINATE if the task has been solved at full satisfaction.\n",
    "   Otherwise, reply CONTINUE, or the why the task is not solved yet\"\"\",\n",
    "   code_execution_config={\"last_n_messages\": 3, \"work_dir\": \"groupchat\"},\n",
    "   llm_config=llm_config,\n",
    ")\n",
    "\n",
    "user_proxy.register_function(function_map={\n",
    "    \"send_image_to_api\": send_image_to_api\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to Assistant):\n",
      "\n",
      "run the registered function send_image_to_api to upload file located in /Users/serkanhaytac/experimental-projects/autogen-habittracker/app_screenshot.jpg and describe the image\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 11-18 12:31:49] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n",
      "\u001b[33mAssistant\u001b[0m (to user_proxy):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: send_image_to_api *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "  \"image_path\": \"/Users/serkanhaytac/experimental-projects/autogen-habittracker/app_screenshot.jpg\"\n",
      "}\n",
      "\u001b[32m******************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION send_image_to_api...\u001b[0m\n",
      "{'choices': [{'finish_details': {'type': 'max_tokens'},\n",
      "              'index': 0,\n",
      "              'message': {'content': 'The image shows a screenshot of a '\n",
      "                                     'habit-tracking or health and fitness '\n",
      "                                     'application on a smartphone. The app is '\n",
      "                                     \"displaying the user's activities for the \"\n",
      "                                     'day, which includes drinking water, '\n",
      "                                     'practicing yoga, drinking fewer sugary '\n",
      "                                     'beverages, eating breakfast, walking, '\n",
      "                                     'running, and meditating. It shows the '\n",
      "                                     'goals and the progress made towards each '\n",
      "                                     'goal for the day. The app also includes '\n",
      "                                     'a calendar view at the top showing the '\n",
      "                                     'days of the week with icons representing '\n",
      "                                     \"the user's consistency in practicing \"\n",
      "                                     'these habits.\\n'\n",
      "                                     '\\n'\n",
      "                                     'Here is a summary of the activities and '\n",
      "                                     \"the user's progress for the day \"\n",
      "                                     'displayed in the app:\\n'\n",
      "                                     '\\n'\n",
      "                                     '- Drink water: The user has consumed '\n",
      "                                     '2,450 ml out of a goal of 3,000 ml.\\n'\n",
      "                                     '- Yoga: The user has completed 25 '\n",
      "                                     'minutes out of a goal of 30 minutes.\\n'\n",
      "                                     '- Drink Less Beverage: The user has not '\n",
      "                                     'consumed any additional beverages '\n",
      "                                     'outside of their goal (0/1 drink).\\n'\n",
      "                                     '- Eat Breakfast: The user has '\n",
      "                                     'successfully eaten breakfast (1/1).\\n'\n",
      "                                     '- Walk: The user has achieved their goal '\n",
      "                                     'of walking 10,000 steps.\\n'\n",
      "                                     '- Run: The user has completed 1 hour out '\n",
      "                                     'of a goal of 1 hour of running.\\n'\n",
      "                                     '- Meditation: The user has completed 30 '\n",
      "                                     'minutes out of a goal of 30 minutes of '\n",
      "                                     'meditation.\\n'\n",
      "                                     '\\n'\n",
      "                                     'Each activity is indicated with streaks, '\n",
      "                                     'such as \"219 Days\" or \"220 Days,\" '\n",
      "                                     'suggesting that the user has been '\n",
      "                                     'consistent with these habits for a '\n",
      "                                     'substantial period of time. The use of '\n",
      "                                     'color coding and',\n",
      "                          'role': 'assistant'}}],\n",
      " 'created': 1700328711,\n",
      " 'id': 'chatcmpl-8MJSZoewoZrgjkynjHvUpXWdxuRz3',\n",
      " 'model': 'gpt-4-1106-vision-preview',\n",
      " 'object': 'chat.completion',\n",
      " 'usage': {'completion_tokens': 300,\n",
      "           'prompt_tokens': 1112,\n",
      "           'total_tokens': 1412}}\n",
      "\u001b[33muser_proxy\u001b[0m (to Assistant):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"send_image_to_api\" *****\u001b[0m\n",
      "None\n",
      "\u001b[32m**************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 11-18 12:31:57] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n",
      "\u001b[33mAssistant\u001b[0m (to user_proxy):\n",
      "\n",
      "I'm sorry, but I can't describe the image as I don't have the capability to view or analyze images. My main function is to assist with text-based tasks and queries.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 11-18 12:31:57] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n",
      "\u001b[33muser_proxy\u001b[0m (to Assistant):\n",
      "\n",
      "CONTINUE\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 11-18 12:31:57] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n",
      "\u001b[33mAssistant\u001b[0m (to user_proxy):\n",
      "\n",
      "Sure, how can I assist you further?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 11-18 12:31:57] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n",
      "\u001b[33muser_proxy\u001b[0m (to Assistant):\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "user_proxy.initiate_chat(\n",
    "    coder,\n",
    "    message=\"\"\"run the registered function send_image_to_api to upload file located in /Users/serkanhaytac/experimental-projects/autogen-habittracker/app_screenshot.jpg and describe the image\"\"\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
